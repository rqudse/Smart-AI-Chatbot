{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddN5v5Fpqa0z",
        "outputId": "b631ae58-ad5b-40ba-a35b-9d23957a029b"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMcbezpnqvM1",
        "outputId": "60fb8bcd-2031-4180-b509-d2ff01b64283"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 421kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/b8/eaf8d169783912bdf319c01a392e03b829673f277a3823b390abf3269bef/feedparser-6.0.4-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2020.12.5)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Building wheels for collected packages: feedfinder2, jieba3k, tinysegmenter, sgmllib3k\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3358 sha256=d99ae110f2c71321f556ac898e2764a4b9438cdc3d16de7af3d7cc4494b58e56\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398404 sha256=7644b5479653fc4490d4eb0737b4486609d81313a0a778770eb0e0695a89ddc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13553 sha256=e28d142e026fb6883b63b7bba8abb5985fb43f9393037bccb85a19d8d9ea86d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=0a58b6983b42505b8034c26fa0816022f7c0add61b4e8ce01131bbfc67599938\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built feedfinder2 jieba3k tinysegmenter sgmllib3k\n",
            "Installing collected packages: feedfinder2, jieba3k, tinysegmenter, cssselect, sgmllib3k, feedparser, requests-file, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmhQp52sqfUn"
      },
      "source": [
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZODcY1ZHqlPw",
        "outputId": "b07801d0-ee91-46b2-b607-f124023b44b1"
      },
      "source": [
        "nltk.download('punkt', quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDLs6BeSqlR-"
      },
      "source": [
        "article = Article('https://www.nationalgeographic.com/environment/article/global-warming-overview')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeT1SbyFqlVX"
      },
      "source": [
        "text = corpus\n",
        "sentence_list = nltk.sent_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tApKugcAqfeD"
      },
      "source": [
        "def greeting_response(text):\n",
        "    text = text.lower()\n",
        "    bot_greetings = ['Hi!', 'Hello!']\n",
        "    user_greetings = ['hi', 'hey', 'hello']\n",
        " \n",
        "    for word in text.split():\n",
        "        if word in user_greetings:\n",
        "            return random.choice(bot_greetings)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0C3ZY_bqfhf"
      },
      "source": [
        "def index_sort(list_var):\n",
        "    lenght = len(list_var)\n",
        "    list_index = list(range(0, lenght))\n",
        " \n",
        "    x = list_var\n",
        "    for i in range(lenght):\n",
        "        for j in range(lenght):\n",
        "            if x[list_index[i]] > x[list_index[j]]:\n",
        "                #Swap\n",
        "                temp = list_index[i]\n",
        "                list_index[i] = list_index[j]\n",
        "                list_index[j] = temp\n",
        " \n",
        "    return list_index"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWRZajyHrYeb"
      },
      "source": [
        "def bot_response(user_input):\n",
        "    user_input = user_input.lower()\n",
        "    sentence_list.append(user_input)\n",
        "    bot_response = ''\n",
        "    cm = CountVectorizer().fit_transform(sentence_list)\n",
        "    similarity_scores = cosine_similarity(cm[-1], cm)\n",
        "    similarity_scores_list = similarity_scores.flatten()\n",
        "    index = index_sort(similarity_scores_list)\n",
        "    index = index[1:]\n",
        "    response_flag = 0\n",
        " \n",
        "    j = 0\n",
        "    for i in range(len(index)):\n",
        "        if similarity_scores_list[index[i]] > 0.0:\n",
        "            bot_response = bot_response+' '+sentence_list[index[i]]\n",
        "            response_flag = 1\n",
        "            j = j+1\n",
        "        if j > 2:\n",
        "            break\n",
        " \n",
        "        if response_flag == 0:\n",
        "            bot_response = bot_response+' '+\"I apologize, I don't understand.\"\n",
        "        sentence_list.remove(user_input)\n",
        " \n",
        "        return bot_response"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-humQjxrYgD",
        "outputId": "4bc2c46f-741b-4a34-d859-bd70a2a8a949"
      },
      "source": [
        "print('I am Bot: I will answer your queries.') \n",
        " \n",
        "exit_list = ['bye']\n",
        " \n",
        " \n",
        "while(True):\n",
        "    user_input = input()\n",
        "    if user_input.lower() in exit_list:\n",
        "        print('Bot:Bye!')\n",
        "        break\n",
        "    else:\n",
        "        if greeting_response(user_input) != None:\n",
        "            print('Bot: '+greeting_response(user_input))\n",
        "        else:\n",
        "            print('Bot: '+bot_response(user_input))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am Bot: I will answer your queries.\n",
            "Hi\n",
            "Bot: Hi!\n",
            "bye\n",
            "Bot:Bye!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZS1_s6jrYjl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}